{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":3163758,"sourceId":5480672,"sourceType":"datasetVersion"}],"dockerImageVersionId":31012,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/umerellous/dl-assignment-03?scriptVersionId=254837724\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"from glob import glob\nimport pandas as pd\nimport numpy as np\nimport mediapipe as mp\nimport cv2\nimport os\nimport json\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.preprocessing import StandardScaler\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"execution":{"iopub.execute_input":"2025-04-26T20:02:12.934274Z","iopub.status.busy":"2025-04-26T20:02:12.934Z","iopub.status.idle":"2025-04-26T20:02:12.938027Z","shell.execute_reply":"2025-04-26T20:02:12.937333Z","shell.execute_reply.started":"2025-04-26T20:02:12.934254Z"},"trusted":true},"outputs":[],"execution_count":9},{"cell_type":"code","source":"base_path = \"/kaggle/input\"\ndef get_pairs(base_path):\n    pairs = []\n    # More flexible folder discovery\n    for root, dirs, files in os.walk(base_path):\n        if 'Videos' in dirs and 'Annotation_files' in dirs:\n            videos_path = os.path.join(root, 'Videos')\n            annotations_path = os.path.join(root, 'Annotation_files')\n            video_formats = ['*.avi', '*.mp4', '*.mov', '*.mkv']\n            video_files = []\n            for fmt in video_formats:\n                video_files.extend(glob(os.path.join(videos_path, fmt)))\n            for video_file in video_files:\n                video_name = os.path.splitext(os.path.basename(video_file))[0]\n                annotation_patterns = [\n                    os.path.join(annotations_path, f\"{video_name}.txt\"),\n                    os.path.join(annotations_path, f\"{video_name.replace('video', 'Video')}.txt\"),\n                    os.path.join(annotations_path, f\"{video_name.lower()}.txt\"),\n                ]\n                for annotation_file in annotation_patterns:\n                    if os.path.exists(annotation_file):\n                        pairs.append((video_file, annotation_file))\n                        break\n                else:\n                    print(f\"Warning: No matching annotation found\")\n    return pairs","metadata":{"execution":{"iopub.execute_input":"2025-04-26T19:43:32.436405Z","iopub.status.busy":"2025-04-26T19:43:32.435634Z","iopub.status.idle":"2025-04-26T19:43:32.442429Z","shell.execute_reply":"2025-04-26T19:43:32.441752Z","shell.execute_reply.started":"2025-04-26T19:43:32.436376Z"},"trusted":true},"outputs":[],"execution_count":5},{"cell_type":"code","source":"# Get pairs\ndataset_pairs = get_pairs(base_path)\ndf = pd.DataFrame(dataset_pairs, columns=['video_path', 'annotation_path'])\ndf['scenario'] = df['video_path'].apply(lambda x: x.split('/')[-3])\ndf.to_csv('video_annotation_mapping.csv', index=False)","metadata":{"execution":{"iopub.execute_input":"2025-04-26T19:43:50.27367Z","iopub.status.busy":"2025-04-26T19:43:50.273388Z","iopub.status.idle":"2025-04-26T19:43:50.836275Z","shell.execute_reply":"2025-04-26T19:43:50.835581Z","shell.execute_reply.started":"2025-04-26T19:43:50.273648Z"},"trusted":true},"outputs":[],"execution_count":6},{"cell_type":"code","source":"print(df.head())","metadata":{"execution":{"iopub.execute_input":"2025-04-26T19:44:08.188107Z","iopub.status.busy":"2025-04-26T19:44:08.187856Z","iopub.status.idle":"2025-04-26T19:44:08.197411Z","shell.execute_reply":"2025-04-26T19:44:08.196665Z","shell.execute_reply.started":"2025-04-26T19:44:08.188088Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["                                          video_path  \\\n","0  /kaggle/input/falldataset-imvia/Home_01/Home_0...   \n","1  /kaggle/input/falldataset-imvia/Home_01/Home_0...   \n","2  /kaggle/input/falldataset-imvia/Home_01/Home_0...   \n","3  /kaggle/input/falldataset-imvia/Home_01/Home_0...   \n","4  /kaggle/input/falldataset-imvia/Home_01/Home_0...   \n","\n","                                     annotation_path scenario  \n","0  /kaggle/input/falldataset-imvia/Home_01/Home_0...  Home_01  \n","1  /kaggle/input/falldataset-imvia/Home_01/Home_0...  Home_01  \n","2  /kaggle/input/falldataset-imvia/Home_01/Home_0...  Home_01  \n","3  /kaggle/input/falldataset-imvia/Home_01/Home_0...  Home_01  \n","4  /kaggle/input/falldataset-imvia/Home_01/Home_0...  Home_01  \n"]}],"execution_count":7},{"cell_type":"code","source":"print(list(df.columns))","metadata":{"execution":{"iopub.execute_input":"2025-04-26T20:04:51.308318Z","iopub.status.busy":"2025-04-26T20:04:51.30767Z","iopub.status.idle":"2025-04-26T20:04:51.31221Z","shell.execute_reply":"2025-04-26T20:04:51.311473Z","shell.execute_reply.started":"2025-04-26T20:04:51.308294Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["['video_path', 'annotation_path', 'scenario']\n"]}],"execution_count":11},{"cell_type":"code","source":"# Mediapipe Pose model\nmp_pose = mp.solutions.pose\npose = mp_pose.Pose(static_image_mode=False)\n\n# Paths\ncsv_path = '/kaggle/working/video_annotation_mapping.csv'\noutput_dir = '/kaggle/working/keypoints_output'\nos.makedirs(output_dir, exist_ok=True)\n\n# Read CSV\ndf = pd.read_csv(csv_path)\n\nfor idx, row in df.iterrows():\n    video_path = row['video_path'] \n    annotation = row['annotation_path'] \n\n    cap = cv2.VideoCapture(video_path)\n    \n    frame_keypoints = []\n    while cap.isOpened():\n        ret, frame = cap.read()\n        if not ret:\n            break\n        \n        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n        result = pose.process(frame_rgb)\n        \n        if result.pose_landmarks:\n            keypoints = [(lm.x, lm.y, lm.z) for lm in result.pose_landmarks.landmark]\n            frame_keypoints.append(keypoints)\n        else:\n            frame_keypoints.append(None) \n        \n    cap.release()\n    \n    # Save keypoints \n    save_data = {\n        'annotation': annotation,\n        'keypoints': frame_keypoints\n    }\n    \n    video_name = os.path.splitext(os.path.basename(video_path))[0]\n    output_path = os.path.join(output_dir, f\"{video_name}_keypoints.json\")\n    \n    with open(output_path, 'w') as f:\n        json.dump(save_data, f)","metadata":{"execution":{"iopub.execute_input":"2025-04-26T20:06:14.865951Z","iopub.status.busy":"2025-04-26T20:06:14.865586Z","iopub.status.idle":"2025-04-26T20:18:28.534609Z","shell.execute_reply":"2025-04-26T20:18:28.533812Z","shell.execute_reply.started":"2025-04-26T20:06:14.865928Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["W0000 00:00:1745697974.974054     146 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1745697975.027970     146 inference_feedback_manager.cc:114] Feedback manager requires a model with a single signature inference. Disabling support for feedback tensors.\n","W0000 00:00:1745697975.050006     147 landmark_projection_calculator.cc:186] Using NORM_RECT without IMAGE_DIMENSIONS is only supported for the square ROI. Provide IMAGE_DIMENSIONS or use PROJECTION_MATRIX.\n","[mp3float @ 0x22b86380] Header missing\n","[mp3float @ 0x22b86380] Header missing\n","[mp3float @ 0x22b86380] Header missing\n","[mp3float @ 0x2240afc0] Header missing\n","[mp3float @ 0x22545e80] Header missing\n","[mp3float @ 0x22416e40] Header missing\n","[mp3float @ 0x22416e40] Header missing\n","[mp3float @ 0x22416e40] Header missing\n","[mp3float @ 0x22416e40] Header missing\n","[mp3float @ 0x22416e40] Header missing\n","[mp3float @ 0x223f1800] Header missing\n","[mp3float @ 0x223f1800] Header missing\n","[mp3float @ 0x223f1800] Header missing\n","[mp3float @ 0x2240afc0] Header missing\n","[mp3float @ 0x223f1800] Header missing\n","[mp3float @ 0x223f1800] Header missing\n","[mp3float @ 0x223f1800] Header missing\n","[mp3float @ 0x223f1800] Header missing\n","[mp3float @ 0x22416e40] Header missing\n","[mp3float @ 0x223f1800] Header missing\n","[mp3float @ 0x22416e40] Header missing\n","[mp3float @ 0x223f1800] Header missing\n","[mp3float @ 0x2229f7c0] Header missing\n","[mp3float @ 0x223d7280] Header missing\n","[mp3float @ 0x223ac600] Header missing\n","[mp3float @ 0x1cd58540] Header missing\n","[mp3float @ 0x223ac600] Header missing\n","[mp3float @ 0x223ac600] Header missing\n","[mp3float @ 0x223ace80] Header missing\n","[mp3float @ 0x223ace80] Header missing\n","[mp3float @ 0x223ace80] Header missing\n","[mp3float @ 0x223ace80] Header missing\n","[mp3float @ 0x2210e480] Header missing\n","[mp3float @ 0x223ace80] Header missing\n","[mp3float @ 0x22297600] Header missing\n","[mp3float @ 0x223ada00] Header missing\n","[mp3float @ 0x223ada00] Header missing\n","[mp3float @ 0x223ada00] Header missing\n","[mp3float @ 0x223ada00] Header missing\n","[mp3float @ 0x223ada00] Header missing\n","[mp3float @ 0x223ada00] Header missing\n","[mp3float @ 0x223ada00] Header missing\n","[mp3float @ 0x223ada00] Header missing\n","[mp3float @ 0x223ada00] Header missing\n","[mp3float @ 0x223ada00] Header missing\n","[mp3float @ 0x223ada00] Header missing\n","[mp3float @ 0x223ada00] Header missing\n","[mp3float @ 0x223ada00] Header missing\n","[mp3float @ 0x223ada00] Header missing\n","[mp3float @ 0x223ada00] Header missing\n","[mp3float @ 0x223ada00] Header missing\n","[mp3float @ 0x223ada00] Header missing\n","[mp3float @ 0x223ada00] Header missing\n","[mp3float @ 0x223ada00] Header missing\n","[mp3float @ 0x223ada00] Header missing\n","[mp3float @ 0x223ada00] Header missing\n","[mp3float @ 0x223ada00] Header missing\n","[mp3float @ 0x223ada00] Header missing\n"]}],"execution_count":14},{"cell_type":"code","source":"# Function to load JSON keypoints from a file\ndef load_keypoints_from_json(json_file):\n    with open(json_file, 'r') as f:\n        data = json.load(f)\n    # Filter out frames with null keypoints\n    keypoints = data[\"keypoints\"]\n    valid_keypoints = []\n    for frame in keypoints:\n        # Filter out frames with any null keypoints\n        if frame is not None and all(kp is not None for kp in frame):\n            valid_keypoints.append(frame)\n    return valid_keypoints","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Helper functions to extract features\ndef calculate_angle(a, b, c):\n    a = np.array(a[:3])  \n    b = np.array(b[:3])\n    c = np.array(c[:3])\n    \n    ba = a - b\n    bc = c - b\n    \n    cosine_angle = np.dot(ba, bc) / (np.linalg.norm(ba) * np.linalg.norm(bc) + 1e-6)\n    angle = np.arccos(np.clip(cosine_angle, -1.0, 1.0))\n    return np.degrees(angle)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def compute_center_of_gravity(landmarks):\n    landmarks_array = np.array([lmk[:3] for lmk in landmarks])  # Only (x, y, z)\n    cog = np.mean(landmarks_array, axis=0)\n    return cog\n\ndef compute_velocity(p1, p2, fps):\n    p1 = np.array(p1[:3])\n    p2 = np.array(p2[:3])\n    return (p2 - p1) * fps\n\ndef compute_acceleration(v1, v2, fps):\n    v1 = np.array(v1)\n    v2 = np.array(v2)\n    return (v2 - v1) * fps","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def extract_features_from_keypoints(video_keypoints, fps=25):\n    features = []\n    prev_frame = None\n    prev_velocity = None\n\n    for frame in video_keypoints:\n        frame_features = {}\n\n        if len(frame) != 33: \n            continue\n        \n        try:\n            LEFT_SHOULDER = 11\n            LEFT_ELBOW = 13\n            LEFT_WRIST = 15\n            RIGHT_SHOULDER = 12\n            RIGHT_ELBOW = 14\n            RIGHT_WRIST = 16\n            LEFT_HIP = 23\n            LEFT_KNEE = 25\n            LEFT_ANKLE = 27\n            RIGHT_HIP = 24\n            RIGHT_KNEE = 26\n            RIGHT_ANKLE = 28\n\n            frame_features['left_elbow_angle'] = calculate_angle(frame[LEFT_SHOULDER], frame[LEFT_ELBOW], frame[LEFT_WRIST])\n            frame_features['right_elbow_angle'] = calculate_angle(frame[RIGHT_SHOULDER], frame[RIGHT_ELBOW], frame[RIGHT_WRIST])\n            frame_features['left_knee_angle'] = calculate_angle(frame[LEFT_HIP], frame[LEFT_KNEE], frame[LEFT_ANKLE])\n            frame_features['right_knee_angle'] = calculate_angle(frame[RIGHT_HIP], frame[RIGHT_KNEE], frame[RIGHT_ANKLE])\n            frame_features['left_shoulder_angle'] = calculate_angle(frame[LEFT_ELBOW], frame[LEFT_SHOULDER], frame[LEFT_HIP])\n            frame_features['right_shoulder_angle'] = calculate_angle(frame[RIGHT_ELBOW], frame[RIGHT_SHOULDER], frame[RIGHT_HIP])\n        except Exception as e:\n            frame_features['left_elbow_angle'] = 0\n            frame_features['right_elbow_angle'] = 0\n            frame_features['left_knee_angle'] = 0\n            frame_features['right_knee_angle'] = 0\n            frame_features['left_shoulder_angle'] = 0\n            frame_features['right_shoulder_angle'] = 0\n\n        # Center of Gravity\n        cog = compute_center_of_gravity(frame)\n        frame_features['cog_x'] = cog[0]\n        frame_features['cog_y'] = cog[1]\n        frame_features['cog_z'] = cog[2]\n\n        # Mean Confidence Score\n        confidence_scores = [kp[3] for kp in frame if len(kp) == 4]  # Get confidence scores\n        frame_features['mean_confidence'] = np.mean(confidence_scores) if confidence_scores else 0.0\n\n        # Velocity\n        if prev_frame is not None:\n            velocities = []\n            for i in range(len(frame)):\n                velocities.append(compute_velocity(prev_frame[i], frame[i], fps))\n            velocities = np.array(velocities)\n            frame_features['mean_velocity'] = np.mean(np.linalg.norm(velocities, axis=1))\n        else:\n            frame_features['mean_velocity'] = 0.0\n\n        # Acceleration\n        if prev_velocity is not None:\n            accelerations = []\n            for i in range(len(velocities)):\n                accelerations.append(compute_acceleration(prev_velocity[i], velocities[i], fps))\n            accelerations = np.array(accelerations)\n            frame_features['mean_acceleration'] = np.mean(np.linalg.norm(accelerations, axis=1))\n        else:\n            frame_features['mean_acceleration'] = 0.0\n\n        # Save\n        prev_frame = frame\n        if 'velocities' in locals():\n            prev_velocity = velocities\n\n        features.append(frame_features)\n\n    return features","metadata":{"execution":{"iopub.execute_input":"2025-04-26T21:46:16.818431Z","iopub.status.busy":"2025-04-26T21:46:16.817901Z","iopub.status.idle":"2025-04-26T21:46:16.832682Z","shell.execute_reply":"2025-04-26T21:46:16.831975Z","shell.execute_reply.started":"2025-04-26T21:46:16.81841Z"},"trusted":true},"outputs":[],"execution_count":60},{"cell_type":"code","source":"# Process all videos in the directory\ndef process_videos_in_directory(directory, fps=25):\n    all_video_features = {}\n\n    for video_file in os.listdir(directory):\n        if video_file.endswith(\".json\"):\n            video_path = os.path.join(directory, video_file)\n            video_keypoints = load_keypoints_from_json(video_path)\n\n            features = extract_features_from_keypoints(video_keypoints, fps=fps)\n            all_video_features[video_file] = features\n\n    return all_video_features","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def save_features_to_csv(features_dict, output_directory):\n    if not os.path.exists(output_directory):\n        os.makedirs(output_directory)\n\n    for video_name, features in features_dict.items():\n        df = pd.DataFrame(features)\n        df['time_step'] = df.index\n        csv_file_path = os.path.join(output_directory, f\"{video_name}_keypoints.csv\")\n        df.to_csv(csv_file_path, index=False)\n        print(f\"Saved features for {video_name} to {csv_file_path}\")\n\n# Example Usage\ndirectory = \"keypoints_output\"\nall_video_features = process_videos_in_directory(directory, fps=25)\nsave_features_to_csv(all_video_features, \"features_output\")","metadata":{"execution":{"iopub.execute_input":"2025-04-26T21:46:22.839704Z","iopub.status.busy":"2025-04-26T21:46:22.839167Z","iopub.status.idle":"2025-04-26T21:46:29.887615Z","shell.execute_reply":"2025-04-26T21:46:29.886901Z","shell.execute_reply.started":"2025-04-26T21:46:22.839682Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Saved features for video (42)_keypoints.json to features_output/video (42)_keypoints.json_keypoints.csv\n","Saved features for video (3)_keypoints.json to features_output/video (3)_keypoints.json_keypoints.csv\n","Saved features for video (31)_keypoints.json to features_output/video (31)_keypoints.json_keypoints.csv\n","Saved features for video (46)_keypoints.json to features_output/video (46)_keypoints.json_keypoints.csv\n","Saved features for video (18)_keypoints.json to features_output/video (18)_keypoints.json_keypoints.csv\n","Saved features for video (11)_keypoints.json to features_output/video (11)_keypoints.json_keypoints.csv\n","Saved features for video (27)_keypoints.json to features_output/video (27)_keypoints.json_keypoints.csv\n","Saved features for video (53)_keypoints.json to features_output/video (53)_keypoints.json_keypoints.csv\n","Saved features for video (26)_keypoints.json to features_output/video (26)_keypoints.json_keypoints.csv\n","Saved features for video (45)_keypoints.json to features_output/video (45)_keypoints.json_keypoints.csv\n","Saved features for video (36)_keypoints.json to features_output/video (36)_keypoints.json_keypoints.csv\n","Saved features for video (49)_keypoints.json to features_output/video (49)_keypoints.json_keypoints.csv\n","Saved features for video (25)_keypoints.json to features_output/video (25)_keypoints.json_keypoints.csv\n","Saved features for video (9)_keypoints.json to features_output/video (9)_keypoints.json_keypoints.csv\n","Saved features for video (34)_keypoints.json to features_output/video (34)_keypoints.json_keypoints.csv\n","Saved features for video (22)_keypoints.json to features_output/video (22)_keypoints.json_keypoints.csv\n","Saved features for video (14)_keypoints.json to features_output/video (14)_keypoints.json_keypoints.csv\n","Saved features for video (21)_keypoints.json to features_output/video (21)_keypoints.json_keypoints.csv\n","Saved features for video (40)_keypoints.json to features_output/video (40)_keypoints.json_keypoints.csv\n","Saved features for video (15)_keypoints.json to features_output/video (15)_keypoints.json_keypoints.csv\n","Saved features for video (50)_keypoints.json to features_output/video (50)_keypoints.json_keypoints.csv\n","Saved features for video (48)_keypoints.json to features_output/video (48)_keypoints.json_keypoints.csv\n","Saved features for video (43)_keypoints.json to features_output/video (43)_keypoints.json_keypoints.csv\n","Saved features for video (23)_keypoints.json to features_output/video (23)_keypoints.json_keypoints.csv\n","Saved features for video (13)_keypoints.json to features_output/video (13)_keypoints.json_keypoints.csv\n","Saved features for video (1)_keypoints.json to features_output/video (1)_keypoints.json_keypoints.csv\n","Saved features for video (57)_keypoints.json to features_output/video (57)_keypoints.json_keypoints.csv\n","Saved features for video (33)_keypoints.json to features_output/video (33)_keypoints.json_keypoints.csv\n","Saved features for video (30)_keypoints.json to features_output/video (30)_keypoints.json_keypoints.csv\n","Saved features for video (2)_keypoints.json to features_output/video (2)_keypoints.json_keypoints.csv\n","Saved features for video (39)_keypoints.json to features_output/video (39)_keypoints.json_keypoints.csv\n","Saved features for video (7)_keypoints.json to features_output/video (7)_keypoints.json_keypoints.csv\n","Saved features for video (54)_keypoints.json to features_output/video (54)_keypoints.json_keypoints.csv\n","Saved features for video (17)_keypoints.json to features_output/video (17)_keypoints.json_keypoints.csv\n","Saved features for video (58)_keypoints.json to features_output/video (58)_keypoints.json_keypoints.csv\n","Saved features for video (47)_keypoints.json to features_output/video (47)_keypoints.json_keypoints.csv\n","Saved features for video (51)_keypoints.json to features_output/video (51)_keypoints.json_keypoints.csv\n","Saved features for video (12)_keypoints.json to features_output/video (12)_keypoints.json_keypoints.csv\n","Saved features for video (16)_keypoints.json to features_output/video (16)_keypoints.json_keypoints.csv\n","Saved features for video (19)_keypoints.json to features_output/video (19)_keypoints.json_keypoints.csv\n","Saved features for video (10)_keypoints.json to features_output/video (10)_keypoints.json_keypoints.csv\n","Saved features for video (60)_keypoints.json to features_output/video (60)_keypoints.json_keypoints.csv\n","Saved features for video (24)_keypoints.json to features_output/video (24)_keypoints.json_keypoints.csv\n","Saved features for video (5)_keypoints.json to features_output/video (5)_keypoints.json_keypoints.csv\n","Saved features for video (32)_keypoints.json to features_output/video (32)_keypoints.json_keypoints.csv\n","Saved features for video (55)_keypoints.json to features_output/video (55)_keypoints.json_keypoints.csv\n","Saved features for video (35)_keypoints.json to features_output/video (35)_keypoints.json_keypoints.csv\n","Saved features for video (8)_keypoints.json to features_output/video (8)_keypoints.json_keypoints.csv\n","Saved features for video (56)_keypoints.json to features_output/video (56)_keypoints.json_keypoints.csv\n","Saved features for video (41)_keypoints.json to features_output/video (41)_keypoints.json_keypoints.csv\n","Saved features for video (44)_keypoints.json to features_output/video (44)_keypoints.json_keypoints.csv\n","Saved features for video (52)_keypoints.json to features_output/video (52)_keypoints.json_keypoints.csv\n","Saved features for video (6)_keypoints.json to features_output/video (6)_keypoints.json_keypoints.csv\n","Saved features for video (59)_keypoints.json to features_output/video (59)_keypoints.json_keypoints.csv\n","Saved features for video (37)_keypoints.json to features_output/video (37)_keypoints.json_keypoints.csv\n","Saved features for video (29)_keypoints.json to features_output/video (29)_keypoints.json_keypoints.csv\n","Saved features for video (20)_keypoints.json to features_output/video (20)_keypoints.json_keypoints.csv\n","Saved features for video (38)_keypoints.json to features_output/video (38)_keypoints.json_keypoints.csv\n","Saved features for video (28)_keypoints.json to features_output/video (28)_keypoints.json_keypoints.csv\n","Saved features for video (4)_keypoints.json to features_output/video (4)_keypoints.json_keypoints.csv\n"]}],"execution_count":61},{"cell_type":"code","source":"# Helper function to create temporal sequences\ndef create_temporal_sequences(df, sequence_length=30):\n    temporal_sequences = []\n    for i in range(len(df) - sequence_length + 1):\n        sequence = df.iloc[i:i+sequence_length].reset_index(drop=True)\n        temporal_sequences.append(sequence)\n    return temporal_sequences\n\n# Process the CSV files to create temporal sequences\ndef process_temporal_sequences(directory, output_directory, sequence_length=30):\n    os.makedirs(output_directory, exist_ok=True)\n    \n    all_temporal_sequences = {}\n\n    for video_file in os.listdir(directory):\n        if video_file.endswith(\".csv\"):\n            video_path = os.path.join(directory, video_file)\n            df = pd.read_csv(video_path)\n\n            if 'time_step' not in df.columns:\n                print(f\"Warning: 'time_step' column not found in {video_file}. Skipping.\")\n                continue\n            \n            temporal_sequences = create_temporal_sequences(df, sequence_length)\n            all_temporal_sequences[video_file] = temporal_sequences\n            \n            # Save temporal sequences to new folder\n            output_video_path = os.path.join(output_directory, video_file.replace('.csv', '_temporal_sequences.csv'))\n            temporal_df = pd.concat(temporal_sequences, ignore_index=True)\n            temporal_df.to_csv(output_video_path, index=False)\n            print(f\"Temporal sequences saved for {video_file} to {output_video_path}\")\n\n    return all_temporal_sequences","metadata":{"execution":{"iopub.execute_input":"2025-04-26T21:47:48.263489Z","iopub.status.busy":"2025-04-26T21:47:48.263174Z","iopub.status.idle":"2025-04-26T21:47:48.271158Z","shell.execute_reply":"2025-04-26T21:47:48.270354Z","shell.execute_reply.started":"2025-04-26T21:47:48.263458Z"},"trusted":true},"outputs":[],"execution_count":62},{"cell_type":"code","source":"# Example Usage\ndirectory = \"features_output\" \noutput_directory = \"sequences_output\" \nall_temporal_sequences = process_temporal_sequences(directory, output_directory, sequence_length=30)","metadata":{"execution":{"iopub.execute_input":"2025-04-26T21:48:07.542138Z","iopub.status.busy":"2025-04-26T21:48:07.541699Z","iopub.status.idle":"2025-04-26T21:48:14.224971Z","shell.execute_reply":"2025-04-26T21:48:14.224289Z","shell.execute_reply.started":"2025-04-26T21:48:07.542111Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Temporal sequences saved for video (27)_keypoints.json_keypoints.csv to sequences_output/video (27)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (24)_keypoints.json_keypoints.csv to sequences_output/video (24)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (20)_keypoints.json_keypoints.csv to sequences_output/video (20)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (35)_keypoints.json_keypoints.csv to sequences_output/video (35)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (47)_keypoints.json_keypoints.csv to sequences_output/video (47)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (18)_keypoints.json_keypoints.csv to sequences_output/video (18)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (52)_keypoints.json_keypoints.csv to sequences_output/video (52)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (16)_keypoints.json_keypoints.csv to sequences_output/video (16)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (32)_keypoints.json_keypoints.csv to sequences_output/video (32)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (31)_keypoints.json_keypoints.csv to sequences_output/video (31)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (13)_keypoints.json_keypoints.csv to sequences_output/video (13)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (14)_keypoints.json_keypoints.csv to sequences_output/video (14)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (51)_keypoints.json_keypoints.csv to sequences_output/video (51)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (37)_keypoints.json_keypoints.csv to sequences_output/video (37)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (56)_keypoints.json_keypoints.csv to sequences_output/video (56)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (38)_keypoints.json_keypoints.csv to sequences_output/video (38)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (1)_keypoints.json_keypoints.csv to sequences_output/video (1)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (49)_keypoints.json_keypoints.csv to sequences_output/video (49)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (5)_keypoints.json_keypoints.csv to sequences_output/video (5)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (28)_keypoints.json_keypoints.csv to sequences_output/video (28)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (39)_keypoints.json_keypoints.csv to sequences_output/video (39)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (36)_keypoints.json_keypoints.csv to sequences_output/video (36)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (26)_keypoints.json_keypoints.csv to sequences_output/video (26)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (30)_keypoints.json_keypoints.csv to sequences_output/video (30)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (44)_keypoints.json_keypoints.csv to sequences_output/video (44)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (58)_keypoints.json_keypoints.csv to sequences_output/video (58)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (54)_keypoints.json_keypoints.csv to sequences_output/video (54)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (53)_keypoints.json_keypoints.csv to sequences_output/video (53)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (2)_keypoints.json_keypoints.csv to sequences_output/video (2)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (12)_keypoints.json_keypoints.csv to sequences_output/video (12)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (41)_keypoints.json_keypoints.csv to sequences_output/video (41)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (42)_keypoints.json_keypoints.csv to sequences_output/video (42)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (57)_keypoints.json_keypoints.csv to sequences_output/video (57)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (9)_keypoints.json_keypoints.csv to sequences_output/video (9)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (43)_keypoints.json_keypoints.csv to sequences_output/video (43)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (17)_keypoints.json_keypoints.csv to sequences_output/video (17)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (25)_keypoints.json_keypoints.csv to sequences_output/video (25)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (8)_keypoints.json_keypoints.csv to sequences_output/video (8)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (10)_keypoints.json_keypoints.csv to sequences_output/video (10)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (34)_keypoints.json_keypoints.csv to sequences_output/video (34)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (33)_keypoints.json_keypoints.csv to sequences_output/video (33)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (21)_keypoints.json_keypoints.csv to sequences_output/video (21)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (3)_keypoints.json_keypoints.csv to sequences_output/video (3)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (29)_keypoints.json_keypoints.csv to sequences_output/video (29)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (55)_keypoints.json_keypoints.csv to sequences_output/video (55)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (50)_keypoints.json_keypoints.csv to sequences_output/video (50)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (60)_keypoints.json_keypoints.csv to sequences_output/video (60)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (6)_keypoints.json_keypoints.csv to sequences_output/video (6)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (45)_keypoints.json_keypoints.csv to sequences_output/video (45)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (22)_keypoints.json_keypoints.csv to sequences_output/video (22)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (48)_keypoints.json_keypoints.csv to sequences_output/video (48)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (40)_keypoints.json_keypoints.csv to sequences_output/video (40)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (7)_keypoints.json_keypoints.csv to sequences_output/video (7)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (4)_keypoints.json_keypoints.csv to sequences_output/video (4)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (23)_keypoints.json_keypoints.csv to sequences_output/video (23)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (11)_keypoints.json_keypoints.csv to sequences_output/video (11)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (46)_keypoints.json_keypoints.csv to sequences_output/video (46)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (59)_keypoints.json_keypoints.csv to sequences_output/video (59)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (15)_keypoints.json_keypoints.csv to sequences_output/video (15)_keypoints.json_keypoints_temporal_sequences.csv\n","Temporal sequences saved for video (19)_keypoints.json_keypoints.csv to sequences_output/video (19)_keypoints.json_keypoints_temporal_sequences.csv\n"]}],"execution_count":63},{"cell_type":"code","source":"def load_temporal_sequences(directory):\n    sequences = []\n    labels = [] \n    \n    for video_file in os.listdir(directory):\n        if video_file.endswith(\".csv\"):\n            video_path = os.path.join(directory, video_file)\n            df = pd.read_csv(video_path)\n            label = 1 if \"fall\" in video_file else 0\n            \n            sequences.append(df.values)\n            labels.append(label) \n            \n    return sequences, labels","metadata":{"execution":{"iopub.execute_input":"2025-04-26T21:50:49.030197Z","iopub.status.busy":"2025-04-26T21:50:49.02961Z","iopub.status.idle":"2025-04-26T21:50:49.034807Z","shell.execute_reply":"2025-04-26T21:50:49.034156Z","shell.execute_reply.started":"2025-04-26T21:50:49.030173Z"},"trusted":true},"outputs":[],"execution_count":65},{"cell_type":"code","source":"directory = \"sequences_output\"\ntemporal_sequences, labels = load_temporal_sequences(directory)\n\n# Pad the sequences to a fixed length\nmax_sequence_length = 100\nX_padded = pad_sequences(temporal_sequences, maxlen=max_sequence_length, dtype='float32', padding='post', truncating='post')\n\n# Convert to numpy arrays for model input\nX = np.array(X_padded)\ny = np.array(labels)","metadata":{"execution":{"iopub.execute_input":"2025-04-26T21:53:05.18256Z","iopub.status.busy":"2025-04-26T21:53:05.182178Z","iopub.status.idle":"2025-04-26T21:53:05.969268Z","shell.execute_reply":"2025-04-26T21:53:05.96869Z","shell.execute_reply.started":"2025-04-26T21:53:05.182528Z"},"trusted":true},"outputs":[],"execution_count":71},{"cell_type":"code","source":"# Standardize the data\nscaler = StandardScaler()\nX_scaled = scaler.fit_transform(X.reshape(X.shape[0], -1))","metadata":{"execution":{"iopub.execute_input":"2025-04-26T21:53:47.092264Z","iopub.status.busy":"2025-04-26T21:53:47.092026Z","iopub.status.idle":"2025-04-26T21:53:47.098702Z","shell.execute_reply":"2025-04-26T21:53:47.098104Z","shell.execute_reply.started":"2025-04-26T21:53:47.092247Z"},"trusted":true},"outputs":[],"execution_count":73},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.execute_input":"2025-04-26T21:54:30.922897Z","iopub.status.busy":"2025-04-26T21:54:30.922298Z","iopub.status.idle":"2025-04-26T21:54:30.927407Z","shell.execute_reply":"2025-04-26T21:54:30.926811Z","shell.execute_reply.started":"2025-04-26T21:54:30.922872Z"},"trusted":true},"outputs":[],"execution_count":75},{"cell_type":"code","source":"clf = RandomForestClassifier(n_estimators=100, random_state=42)\nclf.fit(X_train, y_train)","metadata":{"execution":{"iopub.execute_input":"2025-04-26T21:54:51.754124Z","iopub.status.busy":"2025-04-26T21:54:51.753568Z","iopub.status.idle":"2025-04-26T21:54:51.882714Z","shell.execute_reply":"2025-04-26T21:54:51.882136Z","shell.execute_reply.started":"2025-04-26T21:54:51.754099Z"},"trusted":true},"outputs":[{"data":{"text/html":["<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(random_state=42)</pre></div></div></div></div></div>"],"text/plain":["RandomForestClassifier(random_state=42)"]},"execution_count":77,"metadata":{},"output_type":"execute_result"}],"execution_count":77},{"cell_type":"code","source":"y_pred = clf.predict(X_test)\nprint(classification_report(y_test, y_pred))","metadata":{"execution":{"iopub.execute_input":"2025-04-26T21:59:25.237291Z","iopub.status.busy":"2025-04-26T21:59:25.237028Z","iopub.status.idle":"2025-04-26T21:59:25.254201Z","shell.execute_reply":"2025-04-26T21:59:25.253622Z","shell.execute_reply.started":"2025-04-26T21:59:25.237272Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","           0       1.00      1.00      1.00        12\n","\n","    accuracy                           1.00        12\n","   macro avg       1.00      1.00      1.00        12\n","weighted avg       1.00      1.00      1.00        12\n","\n"]}],"execution_count":null},{"cell_type":"code","source":"# Function to draw keypoints on a given frame\ndef draw_keypoints(frame, keypoints):\n    for point in keypoints:\n        if point is not None:\n            cv2.circle(frame, (int(point[0]), int(point[1])), 5, (0, 0, 255), -1)\n    return frame","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"video_path = \"/kaggle/input/falldataset-imvia/Lecture_room/Lecture room/video (1).avi\"\ncap = cv2.VideoCapture(video_path)\n\n# Save the output with keypoints overlayed\noutput_path = \"output_video.avi\"\nfourcc = cv2.VideoWriter_fourcc(*'XVID')\nfps = int(cap.get(cv2.CAP_PROP_FPS))\nframe_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\nframe_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\nout = cv2.VideoWriter(output_path, fourcc, fps, (frame_width, frame_height))\nprint(f\"Video saved to {output_path}\")","metadata":{"execution":{"execution_failed":"2025-04-26T22:05:25.581Z","iopub.execute_input":"2025-04-26T22:05:24.221725Z","iopub.status.busy":"2025-04-26T22:05:24.220989Z"},"trusted":true},"outputs":[],"execution_count":null}]}